# Recurrent Neural Network (RNN)

A recurrent neural network (RNN) distinguishes itself from traditional neural networks (ANNs) by its application in tasks such as stock price prediction, text generation, transcriptions, and machine translation.

Unlike conventional neural networks, where inputs and outputs operate independently, RNN's output relies on preceding elements within the sequence. Moreover, recurrent networks employ shared parameters across each layer, in contrast to feedforward networks, which have distinct weights for each node. In the RNN, the same weights are applied within each layer, and during gradient descent, adjustments to weights and biases are made individually to minimize loss.

<a href="https://github.com/burcuozek/RNNrepo/blob/main/RNN_Tutorial_StockPrediction.ipynb">RNN_Tutorial_StockPrediction.ipynb</a> is a tutorial, which provides insights into the fundamental components of RNNs and highlights the key distinctions from Artificial Neural Networks (ANN). The practical application involves the analysis of the <a href="https://github.com/burcuozek/RNNrepo/blob/main/Mastercard_stock_history.csv
">Mastercard_stock_history.csv</a> dataset.


<a href="https://github.com/burcuozek/RNNrepo/blob/main/RNN-Merck-StockPrediction.ipynb">RNN-Merck-StockPrediction.ipynb</a> file delves into the theoretical aspects of Recurrent Neural Networks (RNN) and demonstrates its practical application in predicting MERCK stock prices. The associated dataset for this tutorial is available at   <a href="https://github.com/burcuozek/RNNrepo/blob/main/MRK.csv">MRK.csv</a>





